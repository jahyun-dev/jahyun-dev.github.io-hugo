+++
date = "2017-04-15T18:00:00+09:00"
title = "아파치 카프카 스터디 1"
+++

카프카를 서비스에 도입하며 스터디한 내용을 하나하나 정리하려 합니다. 정확하지 않은 부분이 많으니 고려하여 읽어주시길 바랍니다. 수정해야 할 부분은 댓글로 남겨주시면 큰 도움이 됩니다.

본 글은 카프카 0.10.2 버전을 기준으로 작성되었습니다.

## 카프카 메시지의 저장 구조

아파치 카프카는 대량의 데이터 스트림 수집, 처리에 초점을 두고 개발되었다. 이를 위해 로그 데이터 구조를 채택했다. 기존 메시징 시스템보다 우수한 대용량 로그 처리가 가능한 이유가 이러한 구조를 채택한 것이기 때문에 해당 구조에 대해 파악하고 있어야 카프카를 올바르게 사용할 수 있다.

![log anatomy](https://kafka.apache.org/0102/images/log_anatomy.png) 

위는 카프카 토픽의 저장 구조다. 

메시지는 파티션 단위로 브로커 서버의 파일 시스템에 저장된다. replication 설정에 따라 복제되고 fail over가 이루어진다. 파티션 내부에서 메시지는 왼쪽에서 오른쪽으로 추가된 순서대로 저장되며, 토픽을 구독할 때도 마찬가지로 파티션 단위로 데이터를 읽고 커밋한다. 커밋 로그, 저널과 매우 유사하다. 이런 이유로 카프카를 `distributed commit log`라고도 한다.

카프카가 RabbitMQ와 같은 메시징 시스템보다 쓰루풋이 좋은 이유가 이러한 구조 덕분이다. 파일 시스템과 같이 선형적인 읽기, 쓰기에서 높은 처리량을 가져갈 수 있다. 메시지를 발송하거나, 구독하거나, 서버 간의 데이터를 복제할때, 커밋 데이터 수신을 확인하는 과정을 배치 처리해 처리량을 최적화한다. 

또한 메시지를 파일 시스템에 저장하므로 영속성이 보장되고 버퍼로 쓸 수 있다. 프로세스 재시작이나 장애시에도 영향없이 복구 할 수 있다.

브로커 구동 시 설정한 `log.dir`를 들어가 확인해보면 카프카가 메시지를 저장하는 모습을 볼 수 있다.

테스트를 위해 partiton을 3으로, replication factor를 2로 지정하고 `test`라는 토픽을 생성. 브로커 서버 중 하나에 접속해 데이터 디렉토리를 확인하자. 브로커의 수가 셋 이라면 `test-0`, `test-2`와 같이 두 개의 토픽 파티션 디렉토리를 있을 것이다. partition이 3, replicaton factor를 2로 지정했기 때문이다. 이런 디렉토리 하나를 로그 세그먼트라고 부른다. 

로그 세그먼트엔 아래의 세 파일이 있다.

- logs
- index
- timeindex

logs 파일엔 메시지가 저장된다. test 토픽에 메시지를 보내면서 logs 파일을 tail로 확인해보면 메시지의 내용과 함께 메타데이터가 쌓이는 모습을 확인할 수 있다. 

index는 메시지의 오프셋을 인덱싱한 파일이다. 파티션(logs)에서 오프셋에 해당하는 위치를 빠르게 찾기 위해 사용된다. 

timeindex는 index와 유사하나 offset 대신 timestamp 값으로 인덱싱한다. timestamp 기준으로 메시지를 찾아 읽거나, 메시지의 rolling, retention에 활용된다.

## 파티션

위의 구조 탓에  카프카는 토픽 파티션 단위로 메시지를 처리하며 카프카 메시지의 처리량은 파티션과 관련이 크다. 

프로듀서 측면에서 보면 동시에 여러 파티션에 메시지를 써내려갈 수 있기 때문에 compression과 같은 비싼 비용이 드는 동작을 수행할 때 하드웨어 자원을 좀 더 잘 활용할 수 있다.

컨슈머는 토픽 구독 시 파티션 단위로 구독하며 하나의 파티션이 하나의 컨슈머 스레드에 할당되기 때문에 컨슈머 처리량과 파티션은 더욱 밀접한 관계다. 파티션을 세 개 설정했다면 컨슈머가 동시에 읽으며 처리할 수 있는 메시지의 수는 세 개가 된다. 따라서 파티션이 커질수록 컨슈머의 처리량 또한 커진다.

파티션 수는 줄일 수 없고 늘릴 수만 있기 때문에 초기에 파티션 설정을 잘 하는게 중요하다. 파티션이 증가할수록 브로커에서 핸들링해야 하는 파일의 수도 늘어나며 브로커, 주키퍼에서 관리해주는 파티션 수가 증가할수록 리밸런싱 시간도 오래 걸려 비가용 시간이 증가할 수 있다.

카프카는 매우 빠른 처리량을 가지고 있어 대부분의 경우 많은 파티션이 필요하지 않다. 메시지 하나의 처리량이 오래 걸려 처리량이 나오지 않아 파티션의 수를 늘려야 하는 경우라면 카프카가 적절하지 않은 선택일 수 있으므로 다른 메시징 처리 시스템을 고려해 보는 것이 좋다.

## 파티션 설정

적은 수의 파티션을 기본 설정으로 두고 특정 토픽에 대해서만 다른 설정을 적용해야 한다.  메시지 하나의 처리 시간이 긴 경우 파티션을 늘리기보다 컨슈머 측면에서 시간을 줄이는 것을 생각해보자.
벤치마크 결과를 참고해보면, 프로듀서의 경우 파티션 하나에 대해 10mb/s의 성능을 내고 있으므로 벤치마크를 참고해보자. 컨슈머 측면에선 어플리케이션의 특성에 따라 크게 달라질 수 있기 때문에 꼭 테스트를 통해 어느 정도의 파티션 수를 설정해야할지 테스트해보는게 좋다.

컨슈머가 초당 50,000개의 메시지를 처리할 수 있고 필요한 처리량이 초당 500,000이라면 최소 10개의 파티션을 설정하는 식으로 토픽 특성에 맞게 파티션 수를 설정하도록 하자.

## 마치며

카프카는 대량의 로그 데이터를 수집하고 처리하기 위한 플랫폼으로 파일 시스템 구조를 채택해 기존 메시징 시스템과 다른 높은 처리량을 갖게 되었다. 이러한 특성 탓에 높은 처리량을 가진 반면 그에 맞는 단점 역시 존재하므로 저장 구조와 그에 따른 특성을 잘 이해하고 사용해야 한다. 그 중 토픽 파티션의 경우 카프카의 안정성과  메시지의 처리량에 큰 영향을 미치므로 단순하게 높은 값을 설정하기보다 토픽의 특성에 맞게 올바른 설정을 하는게 중요하다.

# 참고자료

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Kafka: The Definitive Guide](http://shop.oreilly.com/product/0636920044123.do)
- [101 ways to configure kafka - badly(kafka Summit)](https://www.slideshare.net/spjelkavik/101-ways-to-configure-kafka-badly-kafka-summit)
- [How to choose the number of topics/partitions in a Kafka cluster?](https://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/)
- [Kafka 운영자가 말하는 처음 접하는 Kafka](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/)
- [Intra-cluster Replication for Apache Kafka](https://www.slideshare.net/junrao/kafka-replication-apachecon2013)
- [Benchmarking Apache Kafka: 2 Million Writes Per Second](https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines)
